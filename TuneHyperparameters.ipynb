{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for NB:\n",
      "{'var_smoothing': 0.3511191734215131}\n",
      "Best parameters for KNN:\n",
      "{'n_neighbors': 8}\n",
      "Best parameters for SVM:\n",
      "{'kernel': 'sigmoid'}\n",
      "Best parameters for MLP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (100,)}\n",
      "Best parameters for DT:\n",
      "{'criterion': 'entropy'}\n",
      "Best parameters for RF:\n",
      "{'criterion': 'entropy'}\n",
      "Best parameters for ADA:\n",
      "{'algorithm': 'SAMME'}\n",
      "Best parameters for LR:\n",
      "{'solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>MLP</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>ADA</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NB   KNN   SVM   MLP    DT    RF   ADA    LR\n",
       "Accuracy   0.76  0.80  0.77  0.80  0.76  0.83  0.85  0.87\n",
       "Precision  0.75  0.80  0.78  0.79  0.75  0.83  0.84  0.87\n",
       "Recall     0.74  0.79  0.74  0.79  0.75  0.82  0.83  0.87\n",
       "F1         0.74  0.79  0.75  0.79  0.75  0.82  0.83  0.87\n",
       "MCC        0.49  0.58  0.52  0.59  0.50  0.64  0.67  0.74"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import   pandas  as  pd\n",
    "import   numpy   as  np\n",
    "import   seaborn as  sb\n",
    "import   matplotlib.pyplot as plt\n",
    "from  sklearn.metrics         import   accuracy_score\n",
    "from  sklearn.metrics         import   precision_score\n",
    "from  sklearn.metrics         import   recall_score\n",
    "from  sklearn.metrics         import   f1_score\n",
    "from  sklearn.metrics         import   matthews_corrcoef\n",
    "from  sklearn.metrics         import   classification_report  \n",
    "from  sklearn.model_selection import   train_test_split\n",
    "from  sklearn.model_selection import   GridSearchCV\n",
    "from  sklearn                 import   metrics\n",
    "from  statistics              import   mean\n",
    "from  sklearn.preprocessing   import   StandardScaler  \n",
    "from  sklearn.naive_bayes     import   GaussianNB\n",
    "from  sklearn.neighbors       import   KNeighborsClassifier\n",
    "from  sklearn.svm             import   SVC  \n",
    "from  sklearn.neural_network  import   MLPClassifier\n",
    "from  sklearn.tree            import   DecisionTreeClassifier\n",
    "from  sklearn.ensemble        import   RandomForestClassifier\n",
    "from  sklearn.ensemble        import   AdaBoostClassifier\n",
    "from  sklearn.linear_model    import   LogisticRegression\n",
    "####\n",
    "class  TuneClass():                        \n",
    "    def CreateDF_split(self, path):\n",
    "        dataset = pd.read_csv(path)\n",
    "        df  = pd.DataFrame(dataset) \n",
    "        dfd = df.drop(['uniprot'], axis=1)\n",
    "        X   = dfd.drop(['target'], axis=1)\n",
    "        y   = dfd['target'] \n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "        scaler = StandardScaler()  \n",
    "        scaler.fit(Xtrain)  \n",
    "        Xtrain = scaler.transform(Xtrain)  \n",
    "        Xtest  = scaler.transform(Xtest)  \n",
    "        return  Xtrain, Xtest, ytrain, ytest\n",
    "    ###\n",
    "    def SetParamtere(self):\n",
    "        nb = {\n",
    "               'var_smoothing': np.logspace(0, -9, num=100)\n",
    "        }\n",
    "        knn = {\n",
    "               'n_neighbors': np.arange(1, 16), \n",
    "               'metric'     : ['euclidean', 'manhattan', 'minkowski','mahalanobis'], \n",
    "               'weights'    : ['uniform', 'distance']  \n",
    "        }\n",
    "        svc = { \n",
    "               'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],          \n",
    "               'C'     : [0.05, 0.1, 0.2, 0.3, 0.25, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "       }\n",
    "        mlp = { \n",
    "               'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "               'solver'            : ['lbfgs', 'sgd', 'adam'],\n",
    "               'activation'        : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "               'learning_rate'     : ['constant', 'adaptive', 'invscaling'],\n",
    "               'alpha'             : [0.0001, 0.05]  \n",
    "        }\n",
    "        dt = { \n",
    "               'criterion'        : ['gini','entropy'],\n",
    "               'splitter'         : ['best', 'random'],\n",
    "               'max_depth'        : np.arange(2, 10),\n",
    "               'min_samples_split': np.arange(0, 10),\n",
    "               'min_samples_leaf' : np.arange(0, 10),\n",
    "               'max_features'     : np.arange(0, 15)\n",
    "        }\n",
    "        rf = { \n",
    "               'criterion'        : ['gini', 'entropy'],\n",
    "               'n_estimators'     : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "               'max_depth'        : [3, 10, 20],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf' : [1, 2, 4],\n",
    "               'max_features'     : ['auto', 'log2']\n",
    "        }\n",
    "        ada = { \n",
    "               'algorithm'        : ['SAMME', 'SAMME.R'],\n",
    "               'n_estimators'     : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]    \n",
    "        }\n",
    "        lr = {\n",
    "               'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "               'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "               'C'      : [0.01, 0.1, 1.0, 2.0]     \n",
    "        }\n",
    "        return  nb, knn, svc, mlp, dt, rf, ada, lr\n",
    "    ###\n",
    "    def Tune(self, model, params, Xtrain, ytrain):\n",
    "        GS = GridSearchCV(model, param_grid=params, cv=10, n_jobs=-1)  \n",
    "        GS.fit(Xtrain, ytrain)\n",
    "        return GS\n",
    "    \n",
    "    def ComputeMesure(self, gs, Xtest, ytest):\n",
    "        ypred = gs.predict(Xtest)\n",
    "        a = round(accuracy_score(ytest, ypred), 2)\n",
    "        p = round(mean(precision_score(ytest, ypred, average=None)), 2)\n",
    "        r = round(mean(recall_score(ytest, ypred, average=None)), 2)\n",
    "        f = round(mean(f1_score(ytest, ypred, average=None)), 2)\n",
    "        m = round(matthews_corrcoef(ytest, ypred), 2)       \n",
    "        return [a, p, r, f, m]\n",
    "    ###\n",
    "    def  ST(self, path):\n",
    "        pnb, pknn, psvc, pmlp, pdt, prf, pada, plr = self.SetParamtere()\n",
    "        Xtrain, Xtest, ytrain, ytest = self.CreateDF_split(path)\n",
    "        print('Best parameters for NB:')\n",
    "        gsNB = self.Tune(GaussianNB(), pnb, Xtrain, ytrain)\n",
    "        bpNB = gsNB.best_params_\n",
    "        print(bpNB)\n",
    "        nb = self.ComputeMesure(gsNB, Xtest, ytest)\n",
    "        print('Best parameters for KNN:')  \n",
    "        gsKNN = self.Tune(KNeighborsClassifier(), pknn, Xtrain, ytrain)\n",
    "        bpKNN = gsKNN.best_params_\n",
    "        print(bpKNN)\n",
    "        knn = self.ComputeMesure( gsKNN, Xtest, ytest)\n",
    "        print('Best parameters for SVM:')\n",
    "        gsSVC = self.Tune(SVC(), psvc, Xtrain, ytrain)\n",
    "        print(gsSVC.best_params_)\n",
    "        svc = self.ComputeMesure(gsSVC, Xtest, ytest)\n",
    "        print('Best parameters for MLP:')\n",
    "        gsMLP = self.Tune(MLPClassifier(), pmlp, Xtrain, ytrain)\n",
    "        print(gsMLP.best_params_)\n",
    "        mlp = self.ComputeMesure(gsMLP, Xtest, ytest)\n",
    "        print('Best parameters for DT:')\n",
    "        gsDT = self.Tune(DecisionTreeClassifier(), pdt, Xtrain, ytrain)\n",
    "        print(gsDT.best_params_)\n",
    "        dt = self.ComputeMesure(gsDT, Xtest, ytest)                \n",
    "        print('Best parameters for RF:')\n",
    "        gsRF = self.Tune(RandomForestClassifier(), prf, Xtrain, ytrain)\n",
    "        print(gsRF.best_params_)\n",
    "        rf = self.ComputeMesure(gsRF, Xtest, ytest)     \n",
    "        print('Best parameters for ADA:')\n",
    "        gsADA = self.Tune(AdaBoostClassifier(), pada, Xtrain, ytrain)\n",
    "        print(gsADA.best_params_)\n",
    "        ada = self.ComputeMesure(gsADA, Xtest, ytest)  \n",
    "        print('Best parameters for LR:')\n",
    "        gsLR = self.Tune(LogisticRegression(), plr, Xtrain, ytrain)\n",
    "        print(gsLR.best_params_)\n",
    "        lr = self.ComputeMesure(gsLR, Xtest, ytest)  \n",
    "        return nb, knn, svc, mlp, dt, rf, ada, lr\n",
    "    \n",
    "    def Main(self, path):\n",
    "        nb, knn, svc, mlp, dt, rf, ada, lr = self.ST(path)\n",
    "        acc = [nb[0], knn[0], svc[0], mlp[0], dt[0], rf[0], ada[0], lr[0]] \n",
    "        pre = [nb[1], knn[1], svc[1], mlp[1], dt[1], rf[1], ada[1], lr[1]] \n",
    "        rec = [nb[2], knn[2], svc[2], mlp[2], dt[2], rf[2], ada[2], lr[2]] \n",
    "        f1  = [nb[3], knn[3], svc[3], mlp[3], dt[3], rf[3], ada[3], lr[3]] \n",
    "        mcc = [nb[4], knn[4], svc[4], mlp[4], dt[4], rf[4], ada[4], lr[4]] \n",
    "        all = [acc, pre, rec, f1, mcc]\n",
    "        model = ['NB', 'KNN', 'SVM', 'MLP', 'DT', 'RF', 'ADA', 'LR']\n",
    "        mes = ['Accuracy', 'Precision', 'Recall', 'F1', 'MCC']\n",
    "        df = pd.DataFrame(all, index=mes, columns=model)\n",
    "        return df\n",
    "  \n",
    "###        \n",
    "obj = TuneClass()      \n",
    "df = obj.Main('D:/GitHub-IBB/DATA/IF.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
